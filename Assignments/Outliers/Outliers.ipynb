{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenge with removing outliers is that there is always some ambiguity on whether or not a specific data point is actually an outlier. For this notebook, we will define an outlier as a data point that falls under one of these 3 categories:\n",
    "1. Data point violates constraints defined by domain knowledge of dataset\n",
    "2. Data point is visually separated from other points on a graph\n",
    "3. Data point fails a statistical test or rule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of outliers is that they affect the mean of the data and lead to bigger losses when training. Therefore, they create bias in our estimates. In this notebook, we are going to look at different methods of dealing with outliers other than OMP. Outliers are a prevalent issue as they occur very commonly across datasets due to issues such as mislabeling of measurements, data corruption and even natural cases such as VIP tickets for events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing of Libraries and Dataset <br>\n",
    "\n",
    "Below we are importing the libraries and providing the helper functions to compare models. We are using the sklearn boston dataset in this assignment. The score_dataset helper function is credited to https://www.kaggle.com/dansbecker/handling-missing-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_target = boston.target\n",
    "boston_df = pd.DataFrame(boston.data)\n",
    "boston_df.columns = boston.feature_names\n",
    "\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us check if there is any obvious data point that violates the domain knowledge of the dataset. __Do any of the min/max of the columns violate the constraints given in the description of the dataset?__ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "One common way of noticing outliers is by graphs and visualizing data. On graphs it is easier to note that points are very far apart allowing us to detect ouliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plots\n",
    "A box plot with iqr ranges is a simple way of noticing points with some statistical reference. The next task involves making a box plot of the variable LSTAT in the dataset. __Comment on the plot.__ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Solution\n",
    "\n",
    "# End Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatter plot of 2 different variables can see outliers that satisfy multiple criteria in addition to showing how a relationship may make a datapoint an outlier. For example an inverse relationship with most points but a certain point has a high value for both of the variables. For this exercise, make a plot between the variables NOX and INDUS and add the best fit line. __Comment on the plot and the best fit line.__ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Solution\n",
    "\n",
    "# End Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score \n",
    "The Z-Score is a statistical metric that determines how far away a point is from the mean. In this case it gives the distance of each point from the mean of the column. For the next task, determine the z values of X_train. <br>\n",
    "_Hint : Use the stats library from scipy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Solution\n",
    "\n",
    "# End Solution\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with this table it is hard to see which points are outliers but we can determine a threshold for choosing outliers. For the purpose of this notebook, the threshold is going to be 3. __Implement a method to remove the outliers from X_train using z. Remember to modify the size of z due to adding the target back into the dataset before removing the rows that have large z values.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_comb = boston_df.copy(deep = True)\n",
    "z_comb['target'] = boston_target\n",
    "# Begin Solution\n",
    "\n",
    "# End Solution\n",
    "print(z_removed_data.shape)\n",
    "z_y_train = z_removed_data['target']\n",
    "z_x_train = z_removed_data.drop(columns = ['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we are not using the target it is important to know how to extract the target and effectively remove the points in the target that correspond to outliers. <br>__How many points were deleted by this outlier removal?__ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQR\n",
    "\n",
    "The IQR is defined as the distance between the first and the third quantile. We can then apply the IQR rule to filter out the small and the big points. For the next task, we are going to look at performing IQR on the dataset. __Calculate the IQR of the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin Solution\n",
    "\n",
    "# End Solution\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove the values out of the IQR rule. Comment on the remaining data points. How does this compare to z score removal?__ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df_iqr = boston_df.copy(deep = True)\n",
    "#Begin Solution\n",
    "\n",
    "# End Solution\n",
    "\n",
    "boston_df_iqr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
